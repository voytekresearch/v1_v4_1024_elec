{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze eye signal data\n",
    "\n",
    "created: November 19, 2024 <br>\n",
    "last modified:  February 28, 2024\n",
    "\n",
    "Start by analyzing a downsampled version of eye data, then introduce full resolution eye data and compare resting state aperiodic activity in eyes open vs close and in specific timepoint when eyes closed become open (or viceversa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import neo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantities as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "from neurodsp.spectral import compute_spectrum\n",
    "from specparam import SpectralModel\n",
    "\n",
    "# custom\n",
    "import sys\n",
    "sys.path.append(\"../../code\")\n",
    "from info import FS\n",
    "from settings import N_JOBS\n",
    "from paths import EXTERNAL_PATH, PROJECT_PATH\n",
    "from utils import load_nix, epoch_neo_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "eye_path = EXTERNAL_PATH + \"/V1_v4_1024_electrode_resting_state_data/data/L_RS_090817/eye_signals/\"\n",
    "\n",
    "lfp_path = EXTERNAL_PATH + \"/V1_v4_1024_electrode_resting_state_data/data/L_RS_090817/LFP/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze eye data\n",
    "Create new nix file containing behavioral states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block with 1 segments\n",
       "name: 'Eye signals'\n",
       "description: 'eye position and diameters'\n",
       "annotations: {'nix_name': 'neo.block.4296992d060d4ee7b15db59fadc15740'}\n",
       "file_datetime: datetime.datetime(2021, 4, 19, 13, 5, 17, 913450)\n",
       "rec_datetime: datetime.datetime(2021, 4, 19, 6, 25, 32)\n",
       "# segments (N=1)\n",
       "0: Segment with 4 analogsignals, 1 epochs\n",
       "   name: 'eye signal segment'\n",
       "   description: 'Segment of eye pos and diam'\n",
       "   annotations: {'nix_name': 'neo.segment.c532f30c3a734eabae2418c49282dada'}\n",
       "   # analogsignals (N=4)\n",
       "   0: AnalogSignal with 1 channels of length 39627730; units mV; datatype int16 \n",
       "      name: 'XPos'\n",
       "      annotations: {'nix_name': 'neo.analogsignal.19582fa74cef491f8a907698b6ad6702'}\n",
       "      sampling rate: 30000.0 Hz\n",
       "      time: 0.0 s to 1320.9243333333334 s\n",
       "   1: AnalogSignal with 1 channels of length 39627730; units mV; datatype int16 \n",
       "      name: 'YPos'\n",
       "      annotations: {'nix_name': 'neo.analogsignal.62564a856339447fa99eb204ee0daddc'}\n",
       "      sampling rate: 30000.0 Hz\n",
       "      time: 0.0 s to 1320.9243333333334 s\n",
       "   2: AnalogSignal with 1 channels of length 39627730; units mV; datatype int16 \n",
       "      name: 'XDiam'\n",
       "      annotations: {'nix_name': 'neo.analogsignal.6ec6601136fb4b00be8f79bbf5e4ad78'}\n",
       "      sampling rate: 30000.0 Hz\n",
       "      time: 0.0 s to 1320.9243333333334 s\n",
       "   3: AnalogSignal with 1 channels of length 39627730; units mV; datatype int16 \n",
       "      name: 'YDiam'\n",
       "      annotations: {'nix_name': 'neo.analogsignal.abc9f6a97ab6401fb7a598b71f6ee986'}\n",
       "      sampling rate: 30000.0 Hz\n",
       "      time: 0.0 s to 1320.9243333333334 s"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with neo.NixIO(eye_path + \"aligned_eye_data.nix\", mode='ro') as nio:\n",
    "    eye_block = nio.read_block()\n",
    "\n",
    "eye_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original datetime: 2021-04-19 06:25:32\n",
      "New datetime: None\n"
     ]
    }
   ],
   "source": [
    "# set datetime to None to avoid errors when saving\n",
    "# Neo Github issue: https://github.com/NeuralEnsemble/python-neo/issues/1198\n",
    "\n",
    "print(f\"Original datetime: {eye_block.rec_datetime}\")\n",
    "\n",
    "# set block and segment datetime to None\n",
    "eye_block.rec_datetime = None\n",
    "for segment in eye_block.segments:\n",
    "    segment.rec_datetime = None\n",
    "\n",
    "print(f\"New datetime: {eye_block.rec_datetime}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pupil diameter for every time point: (39627730, 1)\n"
     ]
    }
   ],
   "source": [
    "# access X and Y pupil diameter\n",
    "xdiam = eye_block.segments[0].analogsignals[2] / 1000\n",
    "ydiam = eye_block.segments[0].analogsignals[3] / 1000\n",
    "xdiam[xdiam < 0] = 0*pq.mV\n",
    "ydiam[ydiam < 0] = 0*pq.mV\n",
    "\n",
    "# we use .magnitude to access values\n",
    "diam = np.sqrt(ydiam.magnitude**2 + xdiam.magnitude**2)\n",
    "print(f\"pupil diameter for every time point: {diam.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estimate behavioural epochs\n",
    "\n",
    "# Empirically estimated thresholds for eye closure, according to Chen et al\n",
    "#   if 'L_RS_090817' in eye_path: thr = 0.101\n",
    "mask = (diam > 0.101)\n",
    "behavioral_state = mask.astype(float)[:, 0]\n",
    "\n",
    "# Smoothen states with sliding window\n",
    "w = 3\n",
    "kernel = [1/w]*w\n",
    "behavioral_state = np.convolve(behavioral_state, kernel, mode='same')\n",
    "behavioral_state[behavioral_state < 0.5] = 0\n",
    "behavioral_state[behavioral_state >= 0.5] = 1\n",
    "\n",
    "# Save signal to block\n",
    "behaviour_anasig = neo.core.AnalogSignal(behavioral_state,\n",
    "                                              units=pq.V,\n",
    "                                              sampling_rate=xdiam.sampling_rate,\n",
    "                                              name='Behavioural state')\n",
    "eye_block.segments[0].analogsignals.append(behaviour_anasig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eyes open or closed measured in binary: [0. 1.] \n",
      "eyes closed: 32473667 \n",
      "eyes open:7154063\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(behavioral_state, return_counts=True)\n",
    "print(f\"Eyes open or closed measured in binary: {unique} \\neyes closed: {counts[0]} \\neyes open:{counts[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segment with 5 analogsignals, 1 epochs\n",
       "name: 'eye signal segment'\n",
       "description: 'Segment of eye pos and diam'\n",
       "annotations: {'nix_name': 'neo.segment.c532f30c3a734eabae2418c49282dada'}\n",
       "# analogsignals (N=5)\n",
       "0: AnalogSignal with 1 channels of length 39627730; units mV; datatype int16 \n",
       "   name: 'XPos'\n",
       "   annotations: {'nix_name': 'neo.analogsignal.19582fa74cef491f8a907698b6ad6702'}\n",
       "   sampling rate: 30000.0 Hz\n",
       "   time: 0.0 s to 1320.9243333333334 s\n",
       "1: AnalogSignal with 1 channels of length 39627730; units mV; datatype int16 \n",
       "   name: 'YPos'\n",
       "   annotations: {'nix_name': 'neo.analogsignal.62564a856339447fa99eb204ee0daddc'}\n",
       "   sampling rate: 30000.0 Hz\n",
       "   time: 0.0 s to 1320.9243333333334 s\n",
       "2: AnalogSignal with 1 channels of length 39627730; units mV; datatype int16 \n",
       "   name: 'XDiam'\n",
       "   annotations: {'nix_name': 'neo.analogsignal.6ec6601136fb4b00be8f79bbf5e4ad78'}\n",
       "   sampling rate: 30000.0 Hz\n",
       "   time: 0.0 s to 1320.9243333333334 s\n",
       "3: AnalogSignal with 1 channels of length 39627730; units mV; datatype int16 \n",
       "   name: 'YDiam'\n",
       "   annotations: {'nix_name': 'neo.analogsignal.abc9f6a97ab6401fb7a598b71f6ee986'}\n",
       "   sampling rate: 30000.0 Hz\n",
       "   time: 0.0 s to 1320.9243333333334 s\n",
       "4: AnalogSignal with 1 channels of length 39627730; units V; datatype float64 \n",
       "   name: 'Behavioural state'\n",
       "   sampling rate: 30000.0 Hz\n",
       "   time: 0.0 s to 1320.9243333333334 s"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that we have 5 analogsignals (our 4 original + behaviour)\n",
    "eye_block.segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block saved to E:/V1_v4_1024_electrode_resting_state_data/data/L_RS_090817/eye_signals/L_RS_090817_aligned_eye_data.nix\n"
     ]
    }
   ],
   "source": [
    "# save file \n",
    "with neo.io.NixIO(eye_path + \"L_RS_090817_aligned_eye_data.nix\", mode='ow') as nio:\n",
    "    nio.write_block(eye_block)\n",
    "\n",
    "print(f\"Block saved to {eye_path}L_RS_090817_aligned_eye_data.nix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define time windows and load LFP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load LFP and eye data \n",
    "fname = lfp_path + \"NSP1_array1_LFP.nix\"\n",
    "lfp_segment, _ = load_nix(fname)\n",
    "lfp_signal = lfp_segment.analogsignals[0]\n",
    "\n",
    "with neo.io.NixIO(eye_path + \"L_RS_090817_aligned_eye_data.nix\", mode='ro') as nio:\n",
    "    eye_block = nio.read_block()\n",
    "eye_signal = eye_block.segments[0].analogsignals[4]\n",
    "\n",
    "# # downsample eye signals to fit LFP\n",
    "# downsample_factor = int(pre_eye_signal.sampling_rate.magnitude / lfp_signal.sampling_rate.magnitude)\n",
    "# if downsample_factor == 60 :\n",
    "#     eye_signal = pre_eye_signal.downsample(downsample_factor)\n",
    "\n",
    "# if len(eye_signal) == len(lfp_signal):\n",
    "#     print(f\"Total values in signal: {len(lfp_signal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment duration: 0.0 s to 1320.926 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Segment duration: {lfp_segment.t_start} to {lfp_segment.t_stop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of changes in behavioral states: 1102 \n",
      "Total time points: 39627730\n"
     ]
    }
   ],
   "source": [
    "# time indices where there is a change from eyes open to eyes closed\n",
    "eye_array = eye_signal.magnitude.flatten()\n",
    "wh = np.where(np.diff(eye_array) != 0)[0]\n",
    "print(f\"Number of changes in behavioral states: {wh.shape[0]} \\nTotal time points: {eye_array.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of changes in behavioral states with 0.5 seconds: 64\n",
      "Number of changes in behavioral states with 1.0 seconds: 31\n",
      "Number of changes in behavioral states with 1.5 seconds: 14\n",
      "Number of changes in behavioral states with 2.0 seconds: 11\n",
      "Number of changes in behavioral states with 2.5 seconds: 7\n",
      "Number of changes in behavioral states with 3.0 seconds: 4\n",
      "Number of changes in behavioral states with 3.5 seconds: 2\n",
      "Number of changes in behavioral states with 4.0 seconds: 2\n",
      "Number of changes in behavioral states with 4.5 seconds: 0\n",
      "Number of changes in behavioral states with 5.0 seconds: 0\n",
      "Number of changes in behavioral states with 5.5 seconds: 0\n",
      "Number of changes in behavioral states with 6.0 seconds: 0\n"
     ]
    }
   ],
   "source": [
    "# find instances where the eyes are open/closed for Xsec duration and then Xsec of the other state\n",
    "DURATION_TIMES = np.arange(0.5,6.5,0.5)\n",
    "\n",
    "instances = np.array([])\n",
    "\n",
    "for t in DURATION_TIMES:\n",
    "    DURATION = t # in seconds \n",
    "\n",
    "    differences = np.diff(wh)\n",
    "    epoch_indices = np.array([])\n",
    "    for i in range(0, len(differences)):\n",
    "        if (differences[i] >= DURATION*30000) & (differences[i-1] >= DURATION*30000):\n",
    "            epoch_indices = np.append(epoch_indices, wh[i])\n",
    "\n",
    "    instances = np.append(instances, epoch_indices.shape[0])\n",
    "\n",
    "    print(f\"Number of changes in behavioral states with {DURATION} seconds: {epoch_indices.shape[0]}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of changes in behavior')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot function of change between set duration of behavioral state and number of changes in behavior for 1 RS session\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(DURATION_TIMES, instances, color=\"#F5466F\")\n",
    "ax.set_xlabel(\"Duration (s)\")\n",
    "ax.set_ylabel(\"Number of changes in behavior\")\n",
    "#ax.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch transition times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a CSV file containing all time windows where there is a 2 second period of eyes in state 1 (either open or closed) and a 2 second transition in state 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of changes in behavioral states with 2 seconds: 11\n"
     ]
    }
   ],
   "source": [
    "# define duration of our window as 2 seconds\n",
    "## this gives us 11 instances of behavioral change for 1 RS session of monkey L\n",
    "\n",
    "DURATION = 2 #seconds\n",
    "differences = np.diff(wh)\n",
    "epoch_indices = np.array([])\n",
    "for i in range(0, len(differences)):\n",
    "    if (differences[i] >= DURATION*30000) & (differences[i-1] >= DURATION*30000):\n",
    "        epoch_indices = np.append(epoch_indices, wh[i])\n",
    "\n",
    "print(f\"Number of changes in behavioral states with {DURATION} seconds: {epoch_indices.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 289.16013333,  293.30373333,  296.10043333,  322.9545    ,\n",
       "        354.903     ,  381.4944    ,  538.64663333,  885.7171    ,\n",
       "       1120.32023333, 1164.14456667, 1225.85996667])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create time stamps from indices\n",
    "time = np.array(eye_signal.times)\n",
    "epoch_times = np.array([])\n",
    "\n",
    "for i in epoch_indices:\n",
    "    timestamp = time[int(i)]\n",
    "    epoch_times = np.append(epoch_times, timestamp)\n",
    "\n",
    "epoch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition ocurrence #1\n",
      "    initialized as eyes closed at 287.16\n",
      "    finalized as eyes open at 291.16\n",
      "transition ocurrence #2\n",
      "    initialized as eyes open at 291.3\n",
      "    finalized as eyes closed at 295.3\n",
      "transition ocurrence #3\n",
      "    initialized as eyes closed at 294.1\n",
      "    finalized as eyes open at 298.1\n",
      "transition ocurrence #4\n",
      "    initialized as eyes open at 320.95\n",
      "    finalized as eyes closed at 324.95\n",
      "transition ocurrence #5\n",
      "    initialized as eyes closed at 352.9\n",
      "    finalized as eyes open at 356.9\n",
      "transition ocurrence #6\n",
      "    initialized as eyes open at 379.49\n",
      "    finalized as eyes closed at 383.49\n",
      "transition ocurrence #7\n",
      "    initialized as eyes closed at 536.65\n",
      "    finalized as eyes open at 540.65\n",
      "transition ocurrence #8\n",
      "    initialized as eyes open at 883.72\n",
      "    finalized as eyes closed at 887.72\n",
      "transition ocurrence #9\n",
      "    initialized as eyes open at 1118.32\n",
      "    finalized as eyes closed at 1122.32\n",
      "transition ocurrence #10\n",
      "    initialized as eyes open at 1162.14\n",
      "    finalized as eyes closed at 1166.14\n",
      "transition ocurrence #11\n",
      "    initialized as eyes closed at 1223.86\n",
      "    finalized as eyes open at 1227.86\n"
     ]
    }
   ],
   "source": [
    "# use time stamps for epoching\n",
    "transition_times = pd.DataFrame(dtype=object)\n",
    "\n",
    "signal_epoch = []\n",
    "signal_time = []\n",
    "behavior_start = []\n",
    "behavior_stop = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "for sec in epoch_times:\n",
    "    count += 1\n",
    "\n",
    "    print(f\"transition ocurrence #{count}\")\n",
    "\n",
    "    t_start = sec - 2\n",
    "    t_stop = sec + 2\n",
    "\n",
    "    lfp_sliced = lfp_signal.time_slice(t_start * pq.s, t_stop * pq.s)\n",
    "    beh_sliced = eye_signal.time_slice(t_start * pq.s, t_stop * pq.s)\n",
    "\n",
    "    signal_epoch.append(lfp_sliced.magnitude)\n",
    "    signal_time.append(lfp_sliced.times.magnitude)\n",
    "\n",
    "    if beh_sliced.magnitude[0] == 0:\n",
    "        print(f\"    initialized as eyes closed at {round(t_start,2)}\")\n",
    "        behavior_start.append(\"closed\")\n",
    "    elif beh_sliced.magnitude[0] == 1:\n",
    "        print(f\"    initialized as eyes open at {round(t_start,2)}\") \n",
    "        behavior_start.append(\"open\")\n",
    "    \n",
    "    if beh_sliced.magnitude[-1] == 0:\n",
    "        print(f\"    finalized as eyes closed at {round(t_stop,2)}\")\n",
    "        behavior_stop.append(\"closed\")\n",
    "    elif beh_sliced.magnitude[-1] == 1:\n",
    "        print(f\"    finalized as eyes open at {round(t_stop,2)}\")\n",
    "        behavior_stop.append(\"open\")\n",
    "    \n",
    "\n",
    "transition_times['state_1'] = behavior_start\n",
    "transition_times['state_2'] = behavior_stop\n",
    "transition_times['lfp'] = signal_epoch\n",
    "transition_times['time'] = signal_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_1</th>\n",
       "      <th>state_2</th>\n",
       "      <th>lfp</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>closed</td>\n",
       "      <td>open</td>\n",
       "      <td>[[38.07482058688473, 30.839792736238156, 33.94...</td>\n",
       "      <td>[287.16, 287.16200000000003, 287.1640000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open</td>\n",
       "      <td>closed</td>\n",
       "      <td>[[-38.49435925946981, -31.330522739270233, -26...</td>\n",
       "      <td>[291.30400000000003, 291.30600000000004, 291.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>closed</td>\n",
       "      <td>open</td>\n",
       "      <td>[[-13.998995810034833, -4.867778710755416, 4.3...</td>\n",
       "      <td>[294.1, 294.10200000000003, 294.10400000000004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open</td>\n",
       "      <td>closed</td>\n",
       "      <td>[[13.206796728673371, 16.882380718237453, 7.48...</td>\n",
       "      <td>[320.954, 320.956, 320.958, 320.96, 320.962, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>closed</td>\n",
       "      <td>open</td>\n",
       "      <td>[[24.951716453766686, 11.349755470718321, 29.0...</td>\n",
       "      <td>[352.904, 352.906, 352.908, 352.90999999999997...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>open</td>\n",
       "      <td>closed</td>\n",
       "      <td>[[19.71325118204737, 33.52533660707827, 15.040...</td>\n",
       "      <td>[379.494, 379.49600000000004, 379.498000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>closed</td>\n",
       "      <td>open</td>\n",
       "      <td>[[49.415765024980956, 37.979291880874314, 12.5...</td>\n",
       "      <td>[536.646, 536.6479999999999, 536.65, 536.65199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>open</td>\n",
       "      <td>closed</td>\n",
       "      <td>[[9.57130154535084, 14.911264675900723, 18.119...</td>\n",
       "      <td>[883.7180000000001, 883.72, 883.7220000000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>open</td>\n",
       "      <td>closed</td>\n",
       "      <td>[[-40.09471336350105, -50.731377867784786, -51...</td>\n",
       "      <td>[1118.32, 1118.322, 1118.3239999999998, 1118.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>open</td>\n",
       "      <td>closed</td>\n",
       "      <td>[[32.95809359004258, 19.346196922785218, 31.01...</td>\n",
       "      <td>[1162.144, 1162.146, 1162.148, 1162.15, 1162.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>closed</td>\n",
       "      <td>open</td>\n",
       "      <td>[[39.175560881266705, 35.794309188242025, 58.9...</td>\n",
       "      <td>[1223.8600000000001, 1223.862, 1223.864, 1223....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_1 state_2                                                lfp  \\\n",
       "0   closed    open  [[38.07482058688473, 30.839792736238156, 33.94...   \n",
       "1     open  closed  [[-38.49435925946981, -31.330522739270233, -26...   \n",
       "2   closed    open  [[-13.998995810034833, -4.867778710755416, 4.3...   \n",
       "3     open  closed  [[13.206796728673371, 16.882380718237453, 7.48...   \n",
       "4   closed    open  [[24.951716453766686, 11.349755470718321, 29.0...   \n",
       "5     open  closed  [[19.71325118204737, 33.52533660707827, 15.040...   \n",
       "6   closed    open  [[49.415765024980956, 37.979291880874314, 12.5...   \n",
       "7     open  closed  [[9.57130154535084, 14.911264675900723, 18.119...   \n",
       "8     open  closed  [[-40.09471336350105, -50.731377867784786, -51...   \n",
       "9     open  closed  [[32.95809359004258, 19.346196922785218, 31.01...   \n",
       "10  closed    open  [[39.175560881266705, 35.794309188242025, 58.9...   \n",
       "\n",
       "                                                 time  \n",
       "0   [287.16, 287.16200000000003, 287.1640000000000...  \n",
       "1   [291.30400000000003, 291.30600000000004, 291.3...  \n",
       "2   [294.1, 294.10200000000003, 294.10400000000004...  \n",
       "3   [320.954, 320.956, 320.958, 320.96, 320.962, 3...  \n",
       "4   [352.904, 352.906, 352.908, 352.90999999999997...  \n",
       "5   [379.494, 379.49600000000004, 379.498000000000...  \n",
       "6   [536.646, 536.6479999999999, 536.65, 536.65199...  \n",
       "7   [883.7180000000001, 883.72, 883.7220000000001,...  \n",
       "8   [1118.32, 1118.322, 1118.3239999999998, 1118.3...  \n",
       "9   [1162.144, 1162.146, 1162.148, 1162.15, 1162.1...  \n",
       "10  [1223.8600000000001, 1223.862, 1223.864, 1223....  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv\n",
    "transition_times.to_csv(PROJECT_PATH + \"/data/results/lfp_eye_arousal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lfp_sliced.magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute spectra\n",
    "\n",
    "calculate and plot spectra from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "transition_times = pd.read_csv(PROJECT_PATH + \"/data/results/lfp_eye_arousal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38.07482059,  30.83979274,  33.94191367, ...,  38.78437854,\n",
       "         37.80898078,  31.10260234],\n",
       "       [ 42.41193393,  32.75362263,  36.55692089, ...,  43.07328905,\n",
       "         41.97401808,  34.50215498],\n",
       "       [ 44.0003779 ,  35.90524987,  38.12755464, ...,  46.25818768,\n",
       "         45.92447606,  37.11186815],\n",
       "       ...,\n",
       "       [-66.34101073, -48.61208412, -53.371726  , ..., -43.09877078,\n",
       "        -54.05323863, -57.34685337],\n",
       "       [-65.90433276, -46.57716112, -49.46347086, ..., -43.96329922,\n",
       "        -52.89856177, -60.12001896],\n",
       "       [-62.7328628 , -42.10789913, -56.77496855, ..., -43.70016399,\n",
       "        -50.30757961, -59.42631566]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_times['lfp'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_spectrum_welch() got an unexpected keyword argument 'n_jobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# compute power spectrum\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m freq, psd \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_spectrum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransition_times\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlfp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_JOBS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\voytek_f1\\lib\\site-packages\\neurodsp\\spectral\\power.py:57\u001b[0m, in \u001b[0;36mcompute_spectrum\u001b[1;34m(sig, fs, method, avg_type, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the power spectral density of a time series.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m>>> freqs, spectrum = compute_spectrum(sig, fs=500)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwelch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compute_spectrum_welch(sig, fs, avg_type\u001b[38;5;241m=\u001b[39mavg_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwavelet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compute_spectrum_wavelet(sig, fs, avg_type\u001b[38;5;241m=\u001b[39mavg_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: compute_spectrum_welch() got an unexpected keyword argument 'n_jobs'"
     ]
    }
   ],
   "source": [
    "# compute power spectrum\n",
    "freq, psd = compute_spectrum(transition_times['lfp'][0], FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bandwidth value 5.0 yields a normalized bandwidth of 0.32 < 0.5, use a value of at least 7.8125",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m BANDWIDTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.0\u001b[39m \u001b[38;5;66;03m# frequency bandwidth of multitaper decomposition\u001b[39;00m\n\u001b[0;32m      3\u001b[0m lfp \u001b[38;5;241m=\u001b[39m transition_times[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfp\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m spectra_i, freq \u001b[38;5;241m=\u001b[39m \u001b[43mpsd_array_multitaper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_JOBS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBANDWIDTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<decorator-gen-184>:10\u001b[0m, in \u001b[0;36mpsd_array_multitaper\u001b[1;34m(x, sfreq, fmin, fmax, bandwidth, adaptive, low_bias, normalization, output, n_jobs, max_iter, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\voytek_f1\\lib\\site-packages\\mne\\time_frequency\\multitaper.py:420\u001b[0m, in \u001b[0;36mpsd_array_multitaper\u001b[1;34m(x, sfreq, fmin, fmax, bandwidth, adaptive, low_bias, normalization, output, n_jobs, max_iter, verbose)\u001b[0m\n\u001b[0;32m    417\u001b[0m dshape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    418\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_times)\n\u001b[1;32m--> 420\u001b[0m dpss, eigvals, adaptive \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_mt_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madaptive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m n_tapers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dpss)\n\u001b[0;32m    423\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(eigvals)[np\u001b[38;5;241m.\u001b[39mnewaxis, :, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[1;32m<decorator-gen-183>:12\u001b[0m, in \u001b[0;36m_compute_mt_params\u001b[1;34m(n_times, sfreq, bandwidth, low_bias, adaptive, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\voytek_f1\\lib\\site-packages\\mne\\time_frequency\\multitaper.py:325\u001b[0m, in \u001b[0;36m_compute_mt_params\u001b[1;34m(n_times, sfreq, bandwidth, low_bias, adaptive, verbose)\u001b[0m\n\u001b[0;32m    323\u001b[0m     half_nbw \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4.\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m half_nbw \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[1;32m--> 325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbandwidth value \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m yields a normalized bandwidth of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m < 0.5, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse a value of at least \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;241m%\u001b[39m (bandwidth, half_nbw, sfreq \u001b[38;5;241m/\u001b[39m n_times))\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# Compute DPSS windows\u001b[39;00m\n\u001b[0;32m    331\u001b[0m n_tapers_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m half_nbw)\n",
      "\u001b[1;31mValueError\u001b[0m: bandwidth value 5.0 yields a normalized bandwidth of 0.32 < 0.5, use a value of at least 7.8125"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "BANDWIDTH = 5.0 # frequency bandwidth of multitaper decomposition\n",
    "lfp = transition_times['lfp'][0]\n",
    "\n",
    "spectra_i, freq = psd_array_multitaper(lfp, FS, n_jobs=N_JOBS,\n",
    "                                                       bandwidth=BANDWIDTH,\n",
    "                                                       verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "Inputs are not the right dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m fm \u001b[38;5;241m=\u001b[39m SpectralModel()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m fm\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[1;32mc:\\users\\andre\\fooof\\specparam\\objs\\fit.py:338\u001b[0m, in \u001b[0;36mSpectralModel.add_data\u001b[1;34m(self, freqs, power_spectrum, freq_range, clear_results)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# If any data is already present, then clear previous data\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# Also clear results, if present, unless indicated not to\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m#   This is to ensure object consistency of all data & results\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_data_results(clear_freqs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_data,\n\u001b[0;32m    334\u001b[0m                          clear_spectrum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_data,\n\u001b[0;32m    335\u001b[0m                          clear_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_model \u001b[38;5;129;01mand\u001b[39;00m clear_results)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreqs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpower_spectrum, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_range, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_res \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower_spectrum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\andre\\fooof\\specparam\\objs\\fit.py:1361\u001b[0m, in \u001b[0;36mSpectralModel._prepare_data\u001b[1;34m(self, freqs, power_spectrum, freq_range, spectra_dim)\u001b[0m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# Check that data have the right dimensionality\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freqs\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (power_spectrum\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m spectra_dim):\n\u001b[1;32m-> 1361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs are not the right dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;66;03m# Check that data sizes are compatible\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (spectra_dim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m freqs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m power_spectrum\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m   1365\u001b[0m     spectra_dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m freqs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m power_spectrum\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[1;31mDataError\u001b[0m: Inputs are not the right dimensions."
     ]
    }
   ],
   "source": [
    "fm = SpectralModel()\n",
    "fm.add_data(freq, psd)\n",
    "fm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downsample eye signals to fit LFP\n",
    "downsample_factor = int(eye_signal.sampling_rate.magnitude / lfp_signal.sampling_rate.magnitude)\n",
    "if downsample_factor == 60 :\n",
    "    downsample_eye = eye_signal.downsample(downsample_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for when creating the epoch object\n",
    "def get_mean_state(diam):\n",
    "    if np.sum(diam <= 0.5) > np.sum(diam > 0.5):\n",
    "        state = 'Closed_eyes'\n",
    "    else:\n",
    "        state = 'Open_eyes'\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalogSignal with 1 channels of length 39627730; units V; datatype float64 \n",
       "name: 'Behavioural state'\n",
       "annotations: {'nix_name': 'neo.analogsignal.6dcd4242b0ad425ea2b787dbf5fc1357'}\n",
       "sampling rate: 30000.0 Hz\n",
       "time: 0.0 s to 1320.9243333333334 s"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create epoch object\n",
    "wh = np.where(np.diff(behavioral_state) != 0)[0]\n",
    "wh.shape\n",
    "#start_time = wh - (duration/2)\n",
    "# edgeindex = [0] + wh.tolist() + [len(behavioural_state)]\n",
    "\n",
    "# # initialise with first slice\n",
    "# i_start = [edgeindex[0]]\n",
    "# i_stop = [edgeindex[1]]\n",
    "# states = [get_mean_state(behavioural_state[edgeindex[0]:edgeindex[1]])]\n",
    "# # Loop over indices, assign states and merge consecutive same-state slices\n",
    "# for startidx, stopidx in zip(edgeindex[1:-1], edgeindex[2:]):\n",
    "#     nextstate = get_mean_state(behavioural_state[startidx:stopidx])\n",
    "#     if nextstate == states[-1]:\n",
    "#         i_stop[-1] = stopidx\n",
    "#     else:\n",
    "#         i_start.append(startidx)\n",
    "#         i_stop.append(stopidx)\n",
    "#         states.append(nextstate)\n",
    "\n",
    "# # Turn index lists into time arrays\n",
    "# start_times = (np.array(i_start) / ydiam.sampling_rate).rescale('s')\n",
    "# stop_times = (np.array(i_stop) / ydiam.sampling_rate).rescale('s')\n",
    "# durs = stop_times - start_times\n",
    "\n",
    "# # Convert into a pandas dataframe,\n",
    "# datadict = {'t_start': start_times.magnitude,\n",
    "#                 't_stop': stop_times.magnitude,\n",
    "#                 'dur': durs.magnitude,\n",
    "#                 'state': states}\n",
    "\n",
    "# epochs = pd.DataFrame(data=datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voytek_f1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
